## 数据结构  
### 逻辑结构  
- 集合结构：数据结构中的元素之间除了“同属一个集合” 的相互关系外，别无其他关系； 
- 线性结构：数据结构中的元素存在一对一的相互关系； 
-. 树形结构：数据结构中的元素存在一对多的相互关系； 
- 图形结构：数据结构中的元素存在多对多的相互关系。  

![逻辑结构](https://gss2.bdstatic.com/9fo3dSag_xI4khGkpoWK1HF6hhy/baike/crop%3D0%2C1%2C733%2C484%3Bc0%3Dbaike92%2C5%2C5%2C92%2C30/sign=3b23b6787e094b36cfdd41ad9efc50e8/a6efce1b9d16fdfaa5df8e49bc8f8c5495ee7be1.jpg)

### 物理结构  
- 顺序存储：把逻辑上相邻的节点存储在物理位置上相邻的存储单元中，结点之间的逻辑关系由存储单元的邻接关系来体现。  
- 链式存储：在计算机中用一组任意的存储单元存储线性表的数据元素(这组存储单元可以是连续的,也可以是不连续的)。 
- 索引存储: 除建立存储结点信息外，还建立附加的索引表来标识结点的地址。 
- 散列存储：根据结点的关键字直接计算出该结点的存储地址。

----
## 算法 
### 特征 
- 有穷性： 一个算法必须保证执行有限步之后结束；
- 确切性： 算法的每一步骤必须有确切的定义；
- 输入：一个算法有0个或多个输入，以刻画运算对象的初始情况，所谓0个输入是指算法本身定除了初始条件；
- 输出：一个算法有一个或多个输出，以反映对输入数据加工后的结果。没有输出的算法是毫无意义的；
- 可行性： 算法原则上能够精确地运行，而且人们用笔和纸做有限次运算后即可完成。

### 设计要求 
- 正确性：算法的正确性是指算法至少具有输入，输出和加工处理无歧义，并且可以正确反映问题的需求，以及正确得到问题的答案。 
1. 算法程序没有语法错误。
2. 算法程序能够根据正确的输入的值得到满足要求的输出结果。 
3. 算法程序能够根据错误的输入的值得到满足规格说明的输出结果。 
4. 算法程序对于精心设计的，极其刁难的测试数据都能满足要求的输出结果。
- 可读性：算法设计的另一个目的是为了便于阅读，理解和沟通，如果写的代码只有你和上帝能看懂，那这个算法只能说明很失败，因为算法越难理解，就越难找到他的bug，对于调试和修改就更难了 
- 健壮性：当输入的数据不合法的时候，算法也能给出相关的处理，而不是产生异常或者莫名起码的错误。 
- 时间效率高和空间存储量低：在满足以上几点以后，我们还可以考虑对算法程序进一步优化，尽量满足时间效率高和空间存储量低的需求。

--- 
## 效率   
事后统计方法：这种方法主要是通过设计好的测试程序和数据，利用计算机计时器对不同算法编制的程序的运行时间进行比较，从而确定算法效率的高低。  
但这种方法显然是有很大缺陷的：  
1. 必须依据算法事先编制好测试程序，通常需要花费大量时间和精力，完了发觉测试的是糟糕的算法，那不是功亏一篑？赔了娘子又折兵？ 
2. 不同测试环境差别不是一般的大！

事前分析估算方法：在计算机程序编写前，依据统计方法对算法进行估算。  
经过总结，我们发现一个高级语言编写的程序在计算机上运行时所消耗的时间取决于下列因素： 
1. 算法采用的策略，方案
2. 编译产生的代码质量 
3. 问题的输入规模
4. 机器执行指令的速度   
由此可见，抛开这些与计算机硬件、软件有关的因素，一个程序的运行时间依赖于算法的好坏和问题的输入规模。（所谓的问题输入规模是指输入量的多少）

### 高斯算法示例分析  
普通算法：  
```java
int i, sum = 0, n = 100;   // 执行1次
for( i=1; i <= n; i++ )    // 执行了n+1次
{
    sum = sum + i;          // 执行n次
}
```
高斯算法：  
```java
int sum = 0, n = 100;     // 执行1次
sum = (1+n)*n/2;          // 执行1次
```  
第一种算法执行了1+(n+1)+n=2n+2次。   
第二种算法，是1+1=2次   
如果我们把循环看做一个整体，忽略头尾判断的开销，那么这两个算法其实就是n和1的差距。    
**问题：**  循环判断在算法1里边执行了n+1次，看起来是个不小的数量，凭什么说忽略就能忽略？  

### 再来一个例子  
```java
int i, j, x=0, sum=0, n=100;
for( i=1; i <= n; i++ ) {
    for( j=1; j <= n; j++ ) {
        x++;
        sum = sum + x;
    }
}
```
这个例子中，循环条件i从1到100，每次都要让j循环100次，如果非常较真的研究总共精确执行次数，那是非常累的。   

另一方面，我们研究算法的复杂度，侧重的是研究算法随着输入规模扩大增长量的一个抽象，而不是精确地定位需要执行多少次，因为如果这样的话，我们就又得考虑回编译器优化等问题，然后，然后就永远也没有然后了！  

所以，对于这个例子的算法，我们可以果断判定需要执行100^2次。    

### 函数的渐进增长  
#### 测试一
假设两个算法的输入规模都是n，算法A要做2n+3次操作，你可以这么理解：先执行n次的循环，执行完成后再有一个n次的循环，最后有3次运算。
算法B要做3n+1次操作，理解同上，你觉得它们哪一个更快些呢？  

![测试一.png](http://upload-images.jianshu.io/upload_images/293077-a1cfc1e935408684.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)  

当n=1时，算法A1效率不如算法B1，当n=2时，两者效率相同；当n>2时，算法A1就开始优于算法B1了，随着n的继续增加，算法A1比算法B1逐步拉大差距。所以总体上算法A1比算法B1优秀。

函数的渐近增长：给定两个函数f(n)和g(n)，如果存在一个整数N，使得对于所有的n>N，f(n)总是比g(n)大，那么，我们说f(n)的增长渐近快于g(n)。  
从刚才的对比中我们还发现，随着n的增大，后面的+3和+1其实是不影响最终的算法变化曲线的。


#### 测试二
第二个测试，算法C是4n+8，算法D是2n^2+1。  
![测试二](http://upload-images.jianshu.io/upload_images/293077-661793a1aea20301.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
我们观察发现，哪怕去掉与n相乘的常数，两者的结果还是没有改变，算法C2的次数随着n的增长，还是远小于算法D2。  
也就是说，与最高次项相乘的常数并不重要，也可以忽略。

#### 测试三
第三个测试，算法E是2n^2+3n+1，算法F是2n^3+3n+1。  
![测试三](http://upload-images.jianshu.io/upload_images/293077-d8c2bc5b90f6b02e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
我们通过观察又发现，最高次项的指数大的，函数随着n的增长，结果也会变得增长特别快。


#### 测试四 
![测试四](http://upload-images.jianshu.io/upload_images/293077-6def1ef22a6fbfcb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这组数据我们看得很清楚，当n的值变得非常大的时候，3n+1已经没法和2n^2的结果相比较，最终几乎可以忽略不计。而算法G在跟算法I基本已经重合了。


#### 结论
于是我们可以得到这样一个结论，判断一个算法的效率时，函数中的常数和其他次要项常常可以忽略，而更应该关注主项（最高项）的阶数。  

注意，判断一个算法好不好，我们只通过少量的数据是不能做出准确判断的，很容易以偏概全。
